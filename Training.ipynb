{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQWh_tBH5Kd4"
      },
      "source": [
        "## Cloning Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m3z1Lty5KAu",
        "outputId": "27864fe2-05dc-47b8-afa7-b970ad7a93c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOv8-multi-task'...\n",
            "remote: Enumerating objects: 1698, done.\u001b[K\n",
            "remote: Counting objects: 100% (290/290), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 1698 (delta 105), reused 194 (delta 49), pack-reused 1408 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1698/1698), 19.55 MiB | 14.50 MiB/s, done.\n",
            "Resolving deltas: 100% (201/201), done.\n",
            "Updating files: 100% (1313/1313), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.8/313.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hFound existing installation: albumentations 1.4.15\n",
            "Uninstalling albumentations-1.4.15:\n",
            "  Successfully uninstalled albumentations-1.4.15\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!git clone https://github.com/JiayuanWang-JW/YOLOv8-multi-task\n",
        "os.chdir('/content/YOLOv8-multi-task')\n",
        "!pip install --quiet -e .\n",
        "os.chdir('/content')\n",
        "!pip install --quiet ultralytics\n",
        "!pip uninstall -y albumentations ## Data augmentations did not work with multitask\n",
        "!rm -r sample_data\n",
        "os.kill(os.getpid(), 9) # Restart Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmgtPIi45oZF"
      },
      "source": [
        "$$$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOqyFjW_5V7A"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cjOT3ei7Nim"
      },
      "source": [
        "**Mount Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cBQ__L9c16",
        "outputId": "0fdaebeb-b2ee-4e3c-def1-8ee89aa5f88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMyUnJrr5hq7"
      },
      "source": [
        "### Copy and unrar Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSQB6b-t5ffz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppb7E5qXEbMJ"
      },
      "outputs": [],
      "source": [
        "## 1 min 21 s\n",
        "!gdown --id 1iBpVko2sehPeOPhQXWaujOpKFQmNvd_m\n",
        "!unrar x -y -idq /content/RailSem19.rar RailSem19\n",
        "!rm /content/RailSem19.rar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJIEayV38BSc"
      },
      "source": [
        "$$$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM3u4_vh5nJu"
      },
      "source": [
        "### Prepare Data Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hz3gyOMEWr0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from random import shuffle\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb-WbyRSFGwV",
        "outputId": "c28a55ad-1b7a-4e27-c453-275a7de5f7c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8500"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mask_files = os.listdir('RailSem19/rs19_masks')\n",
        "json_files = os.listdir('RailSem19/rs19_jsons')\n",
        "len(mask_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esoO0luEFoLd",
        "outputId": "998d6c94-b884-41bf-f20a-edfab901f27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Paths: 7650\n",
            "Validation Paths: 850\n"
          ]
        }
      ],
      "source": [
        "train_ratio = 0.9  # 90% training, 10% validation\n",
        "train_masks, val_masks = train_test_split(mask_files,\n",
        "                                          train_size=train_ratio,\n",
        "                                          random_state=42)\n",
        "\n",
        "print(\"Training Paths:\", len(train_masks))\n",
        "print(\"Validation Paths:\", len(val_masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOW9m-BvFtfN",
        "outputId": "47ae8aee-9b32-4289-9e42-8a223e4d58e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories Created !!!\n"
          ]
        }
      ],
      "source": [
        "def create_directory_structure(root, segmentation_classes):\n",
        "    # Define the main directory structure\n",
        "    dirs = [\n",
        "        f\"{root}/images/train\",\n",
        "        f\"{root}/images/val\",\n",
        "        f\"{root}/detection-object/labels/train\",\n",
        "        f\"{root}/detection-object/labels/val\"\n",
        "    ]\n",
        "\n",
        "    # Add segmentation classes to the structure\n",
        "    for seg_class in segmentation_classes:\n",
        "        dirs.append(f\"{root}/{seg_class}/labels/train\")\n",
        "        dirs.append(f\"{root}/{seg_class}/labels/val\")\n",
        "\n",
        "    # Create the directories\n",
        "    for directory in dirs:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "root = \"dataset_root\"\n",
        "segmentation_classes = [\"track\", \"rail\", \"pole\"] # rename as 'seg-track-02' 'seg-rail-03' 'seg-pole-04'\n",
        "# segmentation_classes = [\"track\", \"rail\", \"vegetation\", \"pole\", \"construction\"]\n",
        "create_directory_structure(root, segmentation_classes)\n",
        "print(\"Directories Created !!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utils Functions**"
      ],
      "metadata": {
        "id": "812U5bf9Qjv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuwFZ3x-GHgp"
      },
      "outputs": [],
      "source": [
        "def polygon2bbox(pnts_draw):\n",
        "      min_x = np.min(pnts_draw[:, 0])\n",
        "      min_y = np.min(pnts_draw[:, 1])\n",
        "      max_x = np.max(pnts_draw[:, 0])\n",
        "      max_y = np.max(pnts_draw[:, 1])\n",
        "      return min_x, min_y, max_x, max_y\n",
        "\n",
        "def json2bbox(inp_path_json):\n",
        "    restricted_classes=['track-sign-front',\n",
        "                        'person-group','person',\n",
        "                        'car', 'truck','train-car',\n",
        "                        'track-signal-front', 'track-signal-back']\n",
        "\n",
        "    inp_json = json.load(open(inp_path_json, 'r'))\n",
        "    _ = {k:[] for k in restricted_classes}\n",
        "    for obj in inp_json[\"objects\"]:\n",
        "        if not obj['label'] in restricted_classes:\n",
        "          continue\n",
        "\n",
        "        if \"boundingbox\" in obj:\n",
        "            _[obj[\"label\"]].append(obj[\"boundingbox\"])\n",
        "\n",
        "        elif \"polygon\" in obj:\n",
        "            pnts_draw = np.around(np.array(obj[\"polygon\"])).astype(np.int32)\n",
        "            min_x, min_y, max_x, max_y = polygon2bbox(pnts_draw)\n",
        "            _[obj[\"label\"]].append([min_x, min_y, max_x, max_y])\n",
        "    return _\n",
        "\n",
        "\n",
        "def box2yolo(x1, y1, x2, y2, image_width, image_height, class_id):\n",
        "    # Compute the center of the bounding box\n",
        "    x_center = (x1 + x2) / 2.0\n",
        "    y_center = (y1 + y2) / 2.0\n",
        "\n",
        "    # Compute the width and height of the bounding box\n",
        "    width = x2 - x1\n",
        "    height = y2 - y1\n",
        "\n",
        "    # Normalize the coordinates\n",
        "    x_center_norm = x_center / image_width\n",
        "    y_center_norm = y_center / image_height\n",
        "    width_norm = width / image_width\n",
        "    height_norm = height / image_height\n",
        "\n",
        "    # YOLO format: class_id, x_center_norm, y_center_norm, width_norm, height_norm\n",
        "    yolo_format = f\"{class_id} {x_center_norm} {y_center_norm} {width_norm} {height_norm}\"\n",
        "    return yolo_format\n",
        "\n",
        "\n",
        "def segment2yolo(coords,image_width, image_height, class_id):\n",
        "    yolo_format = []\n",
        "    for coord in coords:\n",
        "        cnt2yolo = ''.join([f\"{x / image_width} {y / image_height} \" for x, y in coord])\n",
        "        cnt2yolo = f\"{class_id} {cnt2yolo}\"\n",
        "        yolo_format.append(cnt2yolo)\n",
        "    return yolo_format\n",
        "\n",
        "\n",
        "\n",
        "classes_dict = {\n",
        "    ('track-signal-front', 'track-signal-back'):0, # track-signal\n",
        "    ('track-sign-front'):1, # track-sign\n",
        "    ('person-group','person'):2, # person\n",
        "    ('car', 'truck', 'train-car'):3, # vehicule\n",
        "    (3,12):4,        # track\n",
        "    (17,18):5,       # rail\n",
        "    (5):6,           # Pole\n",
        "}\n",
        "\n",
        "def get_class_id(key):\n",
        "    for keys, value in classes_dict.items():\n",
        "        if isinstance(keys, tuple):\n",
        "            if key in keys:\n",
        "                return value\n",
        "        else:\n",
        "            if key == keys:\n",
        "                return value\n",
        "    return None  # Return None if the key is not found\n",
        "\n",
        "class_groups = [[3,12], # track\n",
        "                [17,18], # rail\n",
        "                [5], # Pole\n",
        "                ]\n",
        "\n",
        "key2class = {\n",
        "    'track':4,\n",
        "    'rail':5,\n",
        "    'pole':6,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c3b0dc141629459bb60e6a39a62c74e8",
            "2fe0aa627fca48dfb6678803f33fbc37",
            "7d2dde7f1cc648f895661245c4936b15",
            "493b9d4ac5e04d8391e11e9de0882f1b",
            "cdd372403ee84efc88563483685c017a",
            "22716d9c827548b081e262a79fa18d3d",
            "827746d9cfe94dddb7650cbdd3c0bb09",
            "6e0fb89171da46c0970a8dc2ea3d5ad0",
            "e09236869b854678b07155fa70d97d3c",
            "218a18b659554b4d839cc8e4325d3f78",
            "4f808a8ab4f94888b4aa5ced44559bf1"
          ]
        },
        "id": "ORkp9SneGXUs",
        "outputId": "b7f91a93-0784-4653-e135-013aa37def74"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7650 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b0dc141629459bb60e6a39a62c74e8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "for mask in tqdm(train_masks):\n",
        "\n",
        "      ## Write bbox information to txt file\n",
        "      # open mask\n",
        "      path = os.path.join('RailSem19/rs19_masks',mask)\n",
        "      im_id_map = cv2.imread(path,cv2.IMREAD_GRAYSCALE) #get semantic label map\n",
        "      # open image\n",
        "      img = os.path.join('RailSem19/rs19_jpgs',mask.replace('.png','.jpg'))\n",
        "      shutil.copy(img, 'dataset_root/images/train')\n",
        "      img = np.array(Image.open(img).convert('RGB'))\n",
        "      h,w,_ = img.shape\n",
        "      # open json\n",
        "      json_file = os.path.join('RailSem19/rs19_jsons',mask.replace('.png','.json'))\n",
        "\n",
        "\n",
        "      ## bbox classes\n",
        "      bbox = json2bbox(json_file)\n",
        "      # write bbox annotations\n",
        "      with open(f\"dataset_root/detection-object/labels/train/{mask.replace('.png','.txt')}\",'w') as f:\n",
        "        for key,boxes in bbox.items():\n",
        "            if not boxes:\n",
        "              continue\n",
        "            class_id = get_class_id(key)\n",
        "            for box in boxes:\n",
        "                x1,y1,x2,y2 = box\n",
        "                annot = box2yolo(x1, y1, x2, y2, w, h, class_id)\n",
        "                f.write(f'{annot}\\n')\n",
        "\n",
        "\n",
        "      ## Annotations for the segmentation\n",
        "      polygons = {\n",
        "          'track':[],\n",
        "          'rail':[],\n",
        "          'pole':[],\n",
        "      }\n",
        "      for i,select_classes in enumerate(class_groups):\n",
        "          im_id_map_copy = np.copy(im_id_map)\n",
        "          for select_class in select_classes:\n",
        "              im_id_map_copy[im_id_map_copy == select_class] = 20 # there are 19 classes so 20 is not used\n",
        "\n",
        "          im_id_map_copy[im_id_map_copy != 20] = 0\n",
        "          im_id_map_copy[im_id_map_copy == 20] = 255\n",
        "\n",
        "          contours, hierarchy  = cv2.findContours(im_id_map_copy, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "          for cnt in contours:\n",
        "                      polygon = []\n",
        "                      if cv2.contourArea(cnt) > 200:\n",
        "                        for point in cnt:\n",
        "                            polygon.append(list(point[0]))\n",
        "                        polygons[list(polygons.keys())[i]].append(polygon)\n",
        "\n",
        "      for key,coords in polygons.items():\n",
        "            with open(f\"dataset_root/{key}/labels/train/{mask.replace('.png','.txt')}\",'w') as f:\n",
        "                  if not coords: # check if the ther's segmentation in the image\n",
        "                        continue\n",
        "                  class_id = key2class[key]\n",
        "                  yolo_format = segment2yolo(coords, w, h, class_id)\n",
        "                  f.write('\\n'.join(yolo_format))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9736828d1b894b18a86a8ca8054f1d8a",
            "ec733a9eb10240aab24be7becbdb7d5f",
            "201a98ea709c4b81ba9791a0083f31fb",
            "110b0fb9eac54da2b726edcd51db2132",
            "698291d6a55a4e65acda86b0b197033a",
            "14a17bd33511419e88ba481365efa459",
            "eee87f552fc44629bc03d55d57e6006a",
            "61f66bb798444378b49d87d1af9e0214",
            "89f39c1be0bf4bffb3b35c6d8184232e",
            "708784a7c2f34928b1d7fdb598585ff4",
            "15b87e2a0a5e4833855ec3df95bac8cd"
          ]
        },
        "id": "EzrUV94GG40q",
        "outputId": "8a44f230-64bf-4256-b820-ccf934fa4786"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/850 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9736828d1b894b18a86a8ca8054f1d8a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "for mask in tqdm(val_masks):\n",
        "      ## Write bbox information to txt file\n",
        "      # open mask\n",
        "      path = os.path.join('RailSem19/rs19_masks',mask)\n",
        "      im_id_map = cv2.imread(path,cv2.IMREAD_GRAYSCALE) #get semantic label map\n",
        "      # open image\n",
        "      img = os.path.join('RailSem19/rs19_jpgs',mask.replace('.png','.jpg'))\n",
        "      shutil.copy(img, 'dataset_root/images/val')\n",
        "      img = np.array(Image.open(img).convert('RGB'))\n",
        "      h,w,_ = img.shape\n",
        "      # open json\n",
        "      json_file = os.path.join('RailSem19/rs19_jsons',mask.replace('.png','.json'))\n",
        "\n",
        "      ## bbox classes\n",
        "      bbox = json2bbox(json_file)\n",
        "\n",
        "      with open(f\"dataset_root/detection-object/labels/val/{mask.replace('.png','.txt')}\",'w') as f:\n",
        "        for key,boxes in bbox.items():\n",
        "            if not boxes:\n",
        "              continue\n",
        "            class_id = get_class_id(key)\n",
        "            for box in boxes:\n",
        "                x1,y1,x2,y2 = box\n",
        "                annot = box2yolo(x1, y1, x2, y2, w, h, class_id)\n",
        "                f.write(f'{annot}\\n')\n",
        "\n",
        "\n",
        "      ## Annotations for the segmentation\n",
        "      polygons = {\n",
        "          'track':[],\n",
        "          'rail':[],\n",
        "          'pole':[],\n",
        "      }\n",
        "      for i,select_classes in enumerate(class_groups):\n",
        "          im_id_map_copy = np.copy(im_id_map)\n",
        "          for select_class in select_classes:\n",
        "              im_id_map_copy[im_id_map_copy == select_class] = 20 # there are 19 classes so 20 is not used\n",
        "\n",
        "          im_id_map_copy[im_id_map_copy != 20] = 0\n",
        "          im_id_map_copy[im_id_map_copy == 20] = 255\n",
        "\n",
        "          contours, hierarchy  = cv2.findContours(im_id_map_copy, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "          for cnt in contours:\n",
        "                      polygon = []\n",
        "                      if cv2.contourArea(cnt) > 200:\n",
        "                          for point in cnt:\n",
        "                              polygon.append(list(point[0]))\n",
        "                          polygons[list(polygons.keys())[i]].append(polygon)\n",
        "\n",
        "      for key,coords in polygons.items():\n",
        "            with open(f\"dataset_root/{key}/labels/val/{mask.replace('.png','.txt')}\",'w') as f:\n",
        "                  if not coords: # check if the ther's segmentation in the image\n",
        "                        continue\n",
        "                  class_id = key2class[key]\n",
        "                  yolo_format = segment2yolo(coords, w, h, class_id)\n",
        "                  f.write('\\n'.join(yolo_format))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/RailSem19"
      ],
      "metadata": {
        "id": "g9iYTnsKUMHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVJzF9qM5ybr"
      },
      "source": [
        "**Rename Folders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mQkkMK_IkfY"
      },
      "outputs": [],
      "source": [
        "os.rename(\"/content/dataset_root/track\", \"/content/dataset_root/seg-track-04\")\n",
        "os.rename(\"/content/dataset_root/rail\", \"/content/dataset_root/seg-rail-05\")\n",
        "os.rename(\"/content/dataset_root/pole\", \"/content/dataset_root/seg-pole-06\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiTbXZn9PBGe"
      },
      "source": [
        "**Create yaml file for dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.path.join(\"YOLOv8-multi-task/ultralytics/datasets\", 'railsem19.yaml')\n",
        "yaml_content = \"\"\"path: /content/dataset_root # dataset root dir\n",
        "\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "labels_list:\n",
        "  - detection-object\n",
        "  - seg-track-04\n",
        "  - seg-rail-05\n",
        "  - seg-pole-06\n",
        "\n",
        "tnc: 7  # number of classes\n",
        "nc_list: [4,1,1,1]\n",
        "map: [None,{'4':'0'},{'5':'0'},{'6':'0'}]\n",
        "\n",
        "# Classes for all tasks\n",
        "names:\n",
        "  0: track-signal\n",
        "  1: track-sign\n",
        "  2: person\n",
        "  3: vehicule\n",
        "  4: track  # track class segmentation\n",
        "  5: rail  #  rail class segmentation\n",
        "  6: pole # pole class segmentation\"\"\"\n",
        "\n",
        "# Write the content to the .yaml file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(yaml_content)"
      ],
      "metadata": {
        "id": "OTCewuqI5RRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZowbrtFRBRj"
      },
      "source": [
        "**Correct Concat_dropout Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYX-8GPrRAgd"
      },
      "outputs": [],
      "source": [
        "Concat_dropout_class = \"\"\"\n",
        "class Concat_dropout(nn.Module):\n",
        "    def __init__(self, dimension=1, ch=None):\n",
        "        super().__init__()\n",
        "        self.d = dimension\n",
        "        self.weight = nn.Parameter(torch.rand(1) * 1e-1,\n",
        "                      requires_grad=True)\n",
        "\n",
        "        self.conv = nn.Conv2d(sum(ch),\n",
        "                               ch[0],\n",
        "                               kernel_size=1,\n",
        "                               stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        cdt = torch.sigmoid(self.weight) >= 0.5\n",
        "        return torch.where(cdt,\n",
        "                          self.conv(torch.cat(x, self.d)),\n",
        "                          x[0])\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/YOLOv8-multi-task/ultralytics/nn/modules/conv.py\", 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "class_lines = Concat_dropout_class.splitlines()\n",
        "class_lines = [l + '\\n' for l in class_lines]\n",
        "lines = lines[:-23]+class_lines\n",
        "\n",
        "with open(\"/content/YOLOv8-multi-task/ultralytics/nn/modules/conv.py\", 'w') as file:\n",
        "    file.writelines(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correct TensorBoard Callback**"
      ],
      "metadata": {
        "id": "3JZqbnbgayXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/YOLOv8-multi-task/ultralytics/yolo/utils/callbacks/tensorboard.py\n",
        "!cp \"/content/drive/MyDrive/Stage 2024/tensorboard.py\" /content/YOLOv8-multi-task/ultralytics/yolo/utils/callbacks/tensorboard.py"
      ],
      "metadata": {
        "id": "DLBcE4EtaxjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Model Architecture**"
      ],
      "metadata": {
        "id": "M8UoYhxUy53_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.path.join(\"YOLOv8-multi-task/ultralytics/models/v8\", 'railsem19.yaml')\n",
        "yaml_content = \"\"\"\n",
        "# Parameters\n",
        "######Jiayuan\n",
        "tnc: 7  # number of classes\n",
        "#######\n",
        "\n",
        "scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\n",
        "  # [depth, width, max_channels]\n",
        "  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs\n",
        "  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs\n",
        "  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs\n",
        "  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n",
        "  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\n",
        "\n",
        "scale: n\n",
        "\n",
        "# YOLOv8.0n backbone\n",
        "backbone:\n",
        "  # [from, repeats, module, args]\n",
        "  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2\n",
        "  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4\n",
        "  - [-1, 3, C2f, [128, True]]\n",
        "  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8\n",
        "  - [-1, 6, C2f, [256, True]]\n",
        "  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16\n",
        "  - [-1, 6, C2f, [512, True]]\n",
        "  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32\n",
        "  - [-1, 3, C2f, [1024, True]]\n",
        "  - [-1, 1, SPPF, [1024, 5]]  # 9\n",
        "\n",
        "# YOLOv8.0n head\n",
        "head:\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4\n",
        "  - [-1, 3, C2f, [512]]  # 12\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3\n",
        "  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)\n",
        "\n",
        "  - [-1, 1, Conv, [256, 3, 2]]\n",
        "  - [[-1, 12], 1, Concat, [1]]  # cat head P4\n",
        "  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)\n",
        "\n",
        "  - [-1, 1, Conv, [512, 3, 2]]\n",
        "  - [[-1, 9], 1, Concat, [1]]  # cat head P5\n",
        "  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)\n",
        "\n",
        "\n",
        " # track\n",
        "  - [9, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 6], 1, Concat_dropout, [1]]  # cat backbone P4\n",
        "  - [-1, 3, C2f, [512]]  # 24\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 4], 1, Concat_dropout, [1]]  # cat backbone P3\n",
        "  - [-1, 3, C2f, [256]]  # 27 (P3/8-small)\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  #  for lane segmentation\n",
        "  - [[-1, 2], 1, Concat_dropout, [1]]  #  cat backbone P2\n",
        "  - [-1, 3, C2f, [128]]  # 30 (P2)\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']] #\n",
        "  - [[-1, 0], 1, Concat_dropout, [1]]  #  cat backbone P1\n",
        "  - [-1, 3, C2f, [64]]  # 33 (P1)\n",
        "\n",
        "\n",
        "\n",
        " # rail\n",
        "  - [9, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 6], 1, Concat_dropout, [1]]  # cat backbone P4\n",
        "  - [-1, 3, C2f, [512]]  # 36\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 4], 1, Concat_dropout, [1]]  # cat backbone P3\n",
        "  - [-1, 3, C2f, [256]]  # 39 (P3/8-small)\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 30 for drivable segmentation\n",
        "  - [[-1, 2], 1, Concat_dropout, [1]]\n",
        "  - [-1, 3, C2f, [128]]  # 42 (P2)\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']] #\n",
        "  - [[-1, 0], 1, Concat_dropout, [1]]\n",
        "  - [-1, 3, C2f, [64]]  # 45 (P1)\n",
        "\n",
        "\n",
        "  # pole\n",
        "  - [9, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 6], 1, Concat_dropout, [1]]  # cat backbone P4\n",
        "  - [-1, 3, C2f, [512]]  # 48\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 4], 1, Concat_dropout, [1]]  # cat backbone P3\n",
        "  - [-1, 3, C2f, [256]]  # 51 (P3/8-small)\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 30 for drivable segmentation\n",
        "  - [[-1, 2], 1, Concat_dropout, [1]]\n",
        "  - [-1, 3, C2f, [128]]  # 54 (P2)\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']] #\n",
        "  - [[-1, 0], 1, Concat_dropout, [1]]\n",
        "  - [-1, 3, C2f, [64]]  # 57 (P1)\n",
        "\n",
        "# tasks\n",
        "  - [[15, 18, 21], 1, Detect, [4]]  # 58 Detect(P3, P4, P5)\n",
        "\n",
        "  - [[33], 1, Segment, [1, 32, 256]]  # 59 Track-Segment\n",
        "\n",
        "  - [[45], 1, Segment, [1, 32, 256]]  # 60 Rail-segment\n",
        "\n",
        "  - [[57], 1, Segment, [1, 32, 256]]  # 61 Pole-Segment\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the .yaml file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(yaml_content)"
      ],
      "metadata": {
        "id": "bGgR3EzxqFd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUCdgP6t9C_S"
      },
      "source": [
        "$$$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_wuepF79Dvy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOTlwB90dBHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79aec4bf-0e7c-49e1-8b1b-665876bd604c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/YOLOv8-multi-task/ultralytics/nn/tasks.py:711: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "model = YOLO('/content/drive/MyDrive/Stage 2024/v4.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = model.model.model.state_dict()\n",
        "\n",
        "# Save the state dict to a file\n",
        "torch.save(model_state_dict, '/content/drive/MyDrive/Stage 2024/state_dict.pt')"
      ],
      "metadata": {
        "id": "3M1lcZ-iMWih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.model.state_dict()"
      ],
      "metadata": {
        "id": "8UUGvoSNL2F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTt1WKrk_Bn3"
      },
      "source": [
        "**Initialise Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMWQqXGv9Orm",
        "outputId": "e4ccd3a9-2627-4427-dcf1-28e990fc170b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 23             [-1, 6]  1     98561  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 24                  -1  1    131840  ultralytics.nn.modules.block.C2f             [256, 128, 1]                 \n",
            " 25                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 26             [-1, 4]  1     24705  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 27                  -1  1     33152  ultralytics.nn.modules.block.C2f             [128, 64, 1]                  \n",
            " 28                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 29             [-1, 2]  1      6209  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 30                  -1  1      8384  ultralytics.nn.modules.block.C2f             [64, 32, 1]                   \n",
            " 31                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 32             [-1, 0]  1      1569  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 33                  -1  1      2144  ultralytics.nn.modules.block.C2f             [32, 16, 1]                   \n",
            " 34                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 35             [-1, 6]  1     98561  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 36                  -1  1    131840  ultralytics.nn.modules.block.C2f             [256, 128, 1]                 \n",
            " 37                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 38             [-1, 4]  1     24705  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 39                  -1  1     33152  ultralytics.nn.modules.block.C2f             [128, 64, 1]                  \n",
            " 40                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 41             [-1, 2]  1      6209  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 42                  -1  1      8384  ultralytics.nn.modules.block.C2f             [64, 32, 1]                   \n",
            " 43                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 44             [-1, 0]  1      1569  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 45                  -1  1      2144  ultralytics.nn.modules.block.C2f             [32, 16, 1]                   \n",
            " 46                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 47             [-1, 6]  1     98561  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 48                  -1  1    131840  ultralytics.nn.modules.block.C2f             [256, 128, 1]                 \n",
            " 49                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 50             [-1, 4]  1     24705  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 51                  -1  1     33152  ultralytics.nn.modules.block.C2f             [128, 64, 1]                  \n",
            " 52                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 53             [-1, 2]  1      6209  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 54                  -1  1      8384  ultralytics.nn.modules.block.C2f             [64, 32, 1]                   \n",
            " 55                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 56             [-1, 0]  1      1569  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 57                  -1  1      2144  ultralytics.nn.modules.block.C2f             [32, 16, 1]                   \n",
            " 58        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            " 59                [33]  1      7940  ultralytics.nn.modules.head.Segment          [1, 32, 64, [16]]             \n",
            " 60                [45]  1      7940  ultralytics.nn.modules.head.Segment          [1, 32, 64, [16]]             \n",
            " 61                [57]  1      7940  ultralytics.nn.modules.head.Segment          [1, 32, 64, [16]]             \n",
            "railsem19 summary: 483 layers, 3955140 parameters, 3955076 gradients\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RailModel = YOLO('/content/YOLOv8-multi-task/ultralytics/models/v8/railsem19.yaml',\n",
        "                 task='multi')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BDD100K Weights"
      ],
      "metadata": {
        "id": "YD9Yh3Jsdbn6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMA6qtVE_Dto"
      },
      "source": [
        "**Transfer Weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2vS1_9K-Eta"
      },
      "outputs": [],
      "source": [
        "def get_layer_keys(state_dict_keys, layer_index):\n",
        "    layer_keys = [key for key in state_dict_keys if key.startswith(f'{layer_index}.')]\n",
        "    return layer_keys\n",
        "\n",
        "def transfer_weights_by_index(pretrained_model, new_model, indices):\n",
        "    # Extract state dicts\n",
        "    pretrained_dict = pretrained_model.state_dict()\n",
        "    new_dict = new_model.state_dict()\n",
        "\n",
        "    # Iterate over the specified indices and transfer weights\n",
        "    for index in indices:\n",
        "        # Construct the layer names based on index\n",
        "        layers = get_layer_keys(new_dict,index)\n",
        "\n",
        "        for l in layers:\n",
        "            try:\n",
        "              new_dict[l] = pretrained_dict[l]\n",
        "            except Exception as e:\n",
        "              print(e)\n",
        "    # Update new model's state dict with transferred weights\n",
        "    new_model.load_state_dict(new_dict)\n",
        "\n",
        "# layer index to transfer weights to\n",
        "indices = list(range(46))\n",
        "remove = [23 +i for i in range(0,23,3)] # skip concat_dropout weights\n",
        "remove += list(range(10,22,1)) # skip detection Neck\n",
        "indices = [x for x in indices if x not in remove]\n",
        "\n",
        "transfer_weights_by_index(model.model.model, RailModel.model.model, indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN15bxwf_Fj_"
      },
      "outputs": [],
      "source": [
        "# model = \"/content/drive/MyDrive/Stage 2024/weights/last.pt\" # @param [\"/content/drive/MyDrive/Stage 2024/weights/best.pt\", \"/content/drive/MyDrive/Stage 2024/weights/last.pt\"]\n",
        "# model = YOLO(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CGFeQ3q6AFaX",
        "outputId": "8dd3ffd8-b5ec-44da-dfea-9843a269cdf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.74 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.105 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=multi, mode=train, model=/content/YOLOv8-multi-task/ultralytics/models/v8/railsem19.yaml, data=YOLOv8-multi-task/ultralytics/datasets/railsem19.yaml, epochs=20, patience=50, batch=16, imgsz=(640, 640), save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=/content/drive/MyDrive/Stage 2024/RailModel, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, combine_class=None, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=1, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, speed=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, TL=8.0, FL=24.0, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, binary_mask_threshold=0.5, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Stage 2024/RailModel2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 28.2MB/s]\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 23             [-1, 6]  1     98561  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 24                  -1  1    131840  ultralytics.nn.modules.block.C2f             [256, 128, 1]                 \n",
            " 25                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 26             [-1, 4]  1     24705  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 27                  -1  1     33152  ultralytics.nn.modules.block.C2f             [128, 64, 1]                  \n",
            " 28                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 29             [-1, 2]  1      6209  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 30                  -1  1      8384  ultralytics.nn.modules.block.C2f             [64, 32, 1]                   \n",
            " 31                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 32             [-1, 0]  1      1569  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 33                  -1  1      2144  ultralytics.nn.modules.block.C2f             [32, 16, 1]                   \n",
            " 34                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 35             [-1, 6]  1     98561  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 36                  -1  1    131840  ultralytics.nn.modules.block.C2f             [256, 128, 1]                 \n",
            " 37                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 38             [-1, 4]  1     24705  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 39                  -1  1     33152  ultralytics.nn.modules.block.C2f             [128, 64, 1]                  \n",
            " 40                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 41             [-1, 2]  1      6209  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 42                  -1  1      8384  ultralytics.nn.modules.block.C2f             [64, 32, 1]                   \n",
            " 43                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 44             [-1, 0]  1      1569  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 45                  -1  1      2144  ultralytics.nn.modules.block.C2f             [32, 16, 1]                   \n",
            " 46                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 47             [-1, 6]  1     98561  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 48                  -1  1    131840  ultralytics.nn.modules.block.C2f             [256, 128, 1]                 \n",
            " 49                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 50             [-1, 4]  1     24705  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 51                  -1  1     33152  ultralytics.nn.modules.block.C2f             [128, 64, 1]                  \n",
            " 52                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 53             [-1, 2]  1      6209  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 54                  -1  1      8384  ultralytics.nn.modules.block.C2f             [64, 32, 1]                   \n",
            " 55                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 56             [-1, 0]  1      1569  ultralytics.nn.modules.conv.Concat_dropout   [1]                           \n",
            " 57                  -1  1      2144  ultralytics.nn.modules.block.C2f             [32, 16, 1]                   \n",
            " 58        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            " 59                [33]  1      7940  ultralytics.nn.modules.head.Segment          [1, 32, 64, [16]]             \n",
            " 60                [45]  1      7940  ultralytics.nn.modules.head.Segment          [1, 32, 64, [16]]             \n",
            " 61                [57]  1      7940  ultralytics.nn.modules.head.Segment          [1, 32, 64, [16]]             \n",
            "railsem19 summary: 483 layers, 3955140 parameters, 3955076 gradients\n",
            "\n",
            "WARNING ‚ö†Ô∏è TensorBoard not initialized correctly, not logging this run. division by zero\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 92.2MB/s]\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "WARNING ‚ö†Ô∏è updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 114 weight(decay=0.0), 151 weight(decay=0.0005), 135 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_root/detection-object/labels/train... 7650 images, 2221 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7650/7650 [00:19<00:00, 382.95it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset_root/detection-object/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_root/seg-track-04/labels/train... 7650 images, 5 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7650/7650 [00:31<00:00, 243.22it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset_root/seg-track-04/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_root/seg-rail-05/labels/train... 7650 images, 3 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7650/7650 [00:43<00:00, 176.09it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset_root/seg-rail-05/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_root/seg-pole-06/labels/train... 7650 images, 299 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7650/7650 [00:15<00:00, 504.67it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset_root/seg-pole-06/labels/train.cache\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_root/detection-object/labels/val... 850 images, 237 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 850/850 [00:02<00:00, 313.07it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset_root/detection-object/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_root/seg-track-04/labels/val... 850 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 850/850 [00:08<00:00, 105.71it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset_root/seg-track-04/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_root/seg-rail-05/labels/val... 850 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 850/850 [00:12<00:00, 67.68it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset_root/seg-rail-05/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_root/seg-pole-06/labels/val... 850 images, 31 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 850/850 [00:05<00:00, 143.85it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset_root/seg-pole-06/labels/val.cache\n",
            "Plotting labels to /content/drive/MyDrive/Stage 2024/RailModel2/labels.jpg... \n",
            "Plotting labels to /content/drive/MyDrive/Stage 2024/RailModel2/labels.jpg... \n",
            "Plotting labels to /content/drive/MyDrive/Stage 2024/RailModel2/labels.jpg... \n",
            "Plotting labels to /content/drive/MyDrive/Stage 2024/RailModel2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Stage 2024/RailModel2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss    Tv_loss    FL_loss    Tv_loss    FL_loss    Tv_loss    FL_loss  Instances       Size\n",
            "       1/20      1.62G      4.258      6.494      3.746      1.827      1.694       1.47      1.546      1.456      1.758         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 479/479 [49:07<00:00,  6.15s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [02:04<00:00,  4.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50   mAP50-95\n",
            "                   all        850       1928    0.00188     0.0655    0.00484    0.00153\n",
            "                 track     pixacc      0.935     subacc        0.5        IoU   6.19e-05       mIoU      0.468\n",
            "                  rail     pixacc      0.972     subacc      0.516        IoU     0.0314       mIoU      0.502\n",
            "                  pole     pixacc      0.971     subacc      0.506        IoU     0.0126       mIoU      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss    Tv_loss    FL_loss    Tv_loss    FL_loss    Tv_loss    FL_loss  Instances       Size\n",
            "       2/20      1.47G      3.903      4.558      3.264      1.591       1.54      1.239      1.316      1.279      1.538        550        640:   1%|‚ñè         | 7/479 [00:36<40:36,  5.16s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ca7f095b10cc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/YOLOv8-multi-task/ultralytics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"YOLOv8-multi-task/ultralytics/datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'railsem19.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m RailModel.train(data=data_path,\n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/YOLOv8-multi-task/ultralytics/yolo/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/YOLOv8-multi-task/ultralytics/yolo/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/YOLOv8-multi-task/ultralytics/yolo/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;31m#         print(f\"Parameter '{name}' does not have a gradient.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m######Jiayuan retain_graph=False Free the GPU memory,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;31m###### Due to we just use backward once, so we can safely set the retain_graph=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "sys.path.insert(0, \"/content/YOLOv8-multi-task/ultralytics\")\n",
        "data_path = os.path.join(\"YOLOv8-multi-task/ultralytics/datasets\", 'railsem19.yaml')\n",
        "RailModel.train(data=data_path,\n",
        "                batch=16,\n",
        "                epochs=20,\n",
        "                imgsz=(640,640),\n",
        "                name='/content/drive/MyDrive/Stage 2024/RailModel',\n",
        "                val=True,\n",
        "                task='multi')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO(\"/content/drive/MyDrive/Stage 2024/RailModel/weights/last.pt\")  # load a partially trained model\n",
        "# Resume training\n",
        "results = model.train(resume=True,\n",
        "                      plots=False)"
      ],
      "metadata": {
        "id": "cy-LvcWSR6yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$$$"
      ],
      "metadata": {
        "id": "zjIEjUdYmK1O"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3b0dc141629459bb60e6a39a62c74e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fe0aa627fca48dfb6678803f33fbc37",
              "IPY_MODEL_7d2dde7f1cc648f895661245c4936b15",
              "IPY_MODEL_493b9d4ac5e04d8391e11e9de0882f1b"
            ],
            "layout": "IPY_MODEL_cdd372403ee84efc88563483685c017a"
          }
        },
        "2fe0aa627fca48dfb6678803f33fbc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22716d9c827548b081e262a79fa18d3d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_827746d9cfe94dddb7650cbdd3c0bb09",
            "value": "100%"
          }
        },
        "7d2dde7f1cc648f895661245c4936b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0fb89171da46c0970a8dc2ea3d5ad0",
            "max": 7650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e09236869b854678b07155fa70d97d3c",
            "value": 7650
          }
        },
        "493b9d4ac5e04d8391e11e9de0882f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218a18b659554b4d839cc8e4325d3f78",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f808a8ab4f94888b4aa5ced44559bf1",
            "value": "‚Äá7650/7650‚Äá[15:46&lt;00:00,‚Äá‚Äá8.92it/s]"
          }
        },
        "cdd372403ee84efc88563483685c017a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22716d9c827548b081e262a79fa18d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827746d9cfe94dddb7650cbdd3c0bb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0fb89171da46c0970a8dc2ea3d5ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09236869b854678b07155fa70d97d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "218a18b659554b4d839cc8e4325d3f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f808a8ab4f94888b4aa5ced44559bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9736828d1b894b18a86a8ca8054f1d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec733a9eb10240aab24be7becbdb7d5f",
              "IPY_MODEL_201a98ea709c4b81ba9791a0083f31fb",
              "IPY_MODEL_110b0fb9eac54da2b726edcd51db2132"
            ],
            "layout": "IPY_MODEL_698291d6a55a4e65acda86b0b197033a"
          }
        },
        "ec733a9eb10240aab24be7becbdb7d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a17bd33511419e88ba481365efa459",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eee87f552fc44629bc03d55d57e6006a",
            "value": "100%"
          }
        },
        "201a98ea709c4b81ba9791a0083f31fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f66bb798444378b49d87d1af9e0214",
            "max": 850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89f39c1be0bf4bffb3b35c6d8184232e",
            "value": 850
          }
        },
        "110b0fb9eac54da2b726edcd51db2132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_708784a7c2f34928b1d7fdb598585ff4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_15b87e2a0a5e4833855ec3df95bac8cd",
            "value": "‚Äá850/850‚Äá[01:44&lt;00:00,‚Äá‚Äá6.19it/s]"
          }
        },
        "698291d6a55a4e65acda86b0b197033a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a17bd33511419e88ba481365efa459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee87f552fc44629bc03d55d57e6006a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f66bb798444378b49d87d1af9e0214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f39c1be0bf4bffb3b35c6d8184232e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "708784a7c2f34928b1d7fdb598585ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b87e2a0a5e4833855ec3df95bac8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}