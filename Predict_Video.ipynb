{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning Repo and install requirements"
      ],
      "metadata": {
        "id": "ZUrq1cChAcBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA-8IMi7AWsb",
        "outputId": "efbc4320-137e-4d9b-a877-78b339912933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOv8-multi-task'...\n",
            "remote: Enumerating objects: 1698, done.\u001b[K\n",
            "remote: Counting objects: 100% (290/290), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 1698 (delta 105), reused 196 (delta 49), pack-reused 1408\u001b[K\n",
            "Receiving objects: 100% (1698/1698), 19.55 MiB | 11.13 MiB/s, done.\n",
            "Resolving deltas: 100% (201/201), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m401.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!git clone https://github.com/JiayuanWang-JW/YOLOv8-multi-task\n",
        "os.chdir('/content/YOLOv8-multi-task')\n",
        "!pip install --quiet -e .\n",
        "os.chdir('/content')\n",
        "!pip install --quiet ultralytics\n",
        "# !pip uninstall -y albumentations ## Data augmentations did not work with multitask\n",
        "!rm -r sample_data\n",
        "os.kill(os.getpid(), 9) # Restart Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$$$"
      ],
      "metadata": {
        "id": "W7tLxUIVAgAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc5K90B7Axlb",
        "outputId": "3dea37ed-455e-4742-82b2-5fc06605cdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download Data"
      ],
      "metadata": {
        "id": "oGQcK9FLA2eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1iBpVko2sehPeOPhQXWaujOpKFQmNvd_m\n",
        "!unrar x -y -idq /content/RailSem19.rar RailSem19\n",
        "!rm /content/RailSem19.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxrtvc3WAy0G",
        "outputId": "b312276a-a369-4bb3-fbc4-ab5929f4331b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iBpVko2sehPeOPhQXWaujOpKFQmNvd_m\n",
            "From (redirected): https://drive.google.com/uc?id=1iBpVko2sehPeOPhQXWaujOpKFQmNvd_m&confirm=t&uuid=4af8cbb9-7e3a-467b-8dd0-033b124b2dd7\n",
            "To: /content/RailSem19.rar\n",
            "100% 5.41G/5.41G [00:48<00:00, 110MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$$$"
      ],
      "metadata": {
        "id": "UWjtpSnUA8Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise Model"
      ],
      "metadata": {
        "id": "hoM3VVgIA_k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import torch.nn as nn\n",
        "import ultralytics\n",
        "import sys"
      ],
      "metadata": {
        "id": "h-1wbQIrAt86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/drive/MyDrive/Stage 2024/best 3.pt')"
      ],
      "metadata": {
        "id": "c5rL8EoNAvd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$$$"
      ],
      "metadata": {
        "id": "PQYIrvSeBC-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Video"
      ],
      "metadata": {
        "id": "mHhsD8_pBDyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Warmup Model**"
      ],
      "metadata": {
        "id": "81Uktz-IBkjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on random image to prepare Predictor and AutoBackend Model for Inference\n",
        "res = model.predict(source=np.random.randint(0,256,\n",
        "                                             size=(720,1280,3),\n",
        "                                             dtype=np.uint8),\n",
        "                    imgsz=(640,640),\n",
        "                    name='Rail',\n",
        "                    conf=0.2,\n",
        "                    iou=0.25,\n",
        "                    speed = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GcNAySABhw6",
        "outputId": "58e17899-6ace-49c1-9e09-625d8988dc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 (no detections), 110.0ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics.yolo.data import load_inference_source"
      ],
      "metadata": {
        "id": "HHf7cy2QAffX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "6TcF8PAABH2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper function**"
      ],
      "metadata": {
        "id": "eICN3Wu5BF61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_video(video_path):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Check if the video file opened successfully\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    print(f\"Video Path: {video_path}\")\n",
        "    print(f\"Frame Count: {frame_count}\")\n",
        "    print(f\"Frame Rate: {frame_rate} fps\")\n",
        "    print(f\"Frame Dimensions: {width}x{height}\")\n",
        "\n",
        "    # Close the video file\n",
        "    cap.release()\n",
        "    return frame_count,frame_rate"
      ],
      "metadata": {
        "id": "oZatqsznAmuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Dataset from the video**"
      ],
      "metadata": {
        "id": "JgnusqOnBT66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = \"ligne 14 cropped.MP4\" # Path to video\n",
        "dataset = load_inference_source(source=source,\n",
        "                                imgsz=model.predictor.imgsz,\n",
        "                                vid_stride=model.predictor.args.vid_stride)\n",
        "frame_count,frame_rate = read_video(source)"
      ],
      "metadata": {
        "id": "UQ6VhFPAAp2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Parameters**"
      ],
      "metadata": {
        "id": "BlIa5JHBBz1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_map = {\n",
        "    1: (152, 251, 152), # Track\n",
        "    2: (255, 255, 255),  # Rail\n",
        "    3: (0,0,255) # Pole\n",
        "}\n",
        "\n",
        "alpha = 0.2\n",
        "model.predictor.args.conf = 0.2\n",
        "model.predictor.args.iou = 0.2"
      ],
      "metadata": {
        "id": "eG0Nc--GBzRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict Frames**"
      ],
      "metadata": {
        "id": "hiFzeXKoB4WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "for batch in tqdm(dataset,total=frame_count):\n",
        "\n",
        "  path, im0s, vid_cap, s = batch\n",
        "  im0s = cv2.cvtColor(im0s[0], cv2.COLOR_RGB2BGR)\n",
        "  im0s = [cv2.resize(im0s, (1280, 720))]\n",
        "  im = model.predictor.preprocess(im0s)\n",
        "  preds = model.predictor.model(im)\n",
        "\n",
        "  results = []\n",
        "  for i, pred in enumerate(preds):\n",
        "      if isinstance(pred, tuple):\n",
        "          pred = model.predictor.postprocess_det(pred, im, im0s)\n",
        "          results.append(pred)\n",
        "      else:\n",
        "          pred = model.predictor.postprocess_seg(pred)\n",
        "          results.append(pred)\n",
        "\n",
        "  # extract mask from preds\n",
        "  mask = np.zeros(shape=(im0s[0].shape[:-1]),dtype=np.uint8)\n",
        "  for i in range(len(results)-1):\n",
        "    pred_mask = results[i+1].squeeze().cpu().numpy().astype(np.uint8)\n",
        "    mask[pred_mask == 1] = i+1\n",
        "\n",
        "\n",
        "  rgb_mask = np.zeros(im0s[0].shape, dtype=np.uint8)\n",
        "\n",
        "  for value, color in color_map.items():\n",
        "      rgb_mask[mask == value] = color\n",
        "  # relay mask on the original image\n",
        "  blended_image = np.array(Image.blend(Image.fromarray(im0s[0]), Image.fromarray(rgb_mask), alpha))\n",
        "  results[0][0].orig_img = blended_image # cv2.cvtColor(blended_image, cv2.COLOR_RGB2BGR)\n",
        "  frames.append(results[0][0].plot()[...,::-1])"
      ],
      "metadata": {
        "id": "_U0wKhAvBWHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Predicted Video**"
      ],
      "metadata": {
        "id": "kCAQipqeCAu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = cv2.VideoWriter(f\"pred_{source}\",cv2.VideoWriter_fourcc(*'DIVX'), frame_rate, (1280, 720))\n",
        "\n",
        "for i in tqdm(range(len(frames))):\n",
        "    out.write(frames[i])\n",
        "out.release()\n",
        "print(\"Video saved successfully !!!\")"
      ],
      "metadata": {
        "id": "zPJeZNpTCAKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}